{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3ZJPQcFDnub1PBhkaRkOh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MonkeyWrenchGang/PythonBootcamp/blob/main/day_3/3_8_Dealing_with_Nulls.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pandas and Null Values\n",
        "\n",
        "- Pandas easily handles missing or null values in datasets.\n",
        "- Null values can occur due to various reasons, such as incomplete data, data corruption, or data extraction issues.\n",
        "- Pandas represents null values as `NaN` (Not a Number) or `None`.\n",
        "\n",
        "### Common Operations to Handle Nulls\n",
        "\n",
        "1. Checking for Null Values:\n",
        "   - `df.isnull()` or `isna()`: Returns a DataFrame of the same shape as the input DataFrame, with True where null values are present.\n",
        "   - `df.notnull()` or `.notna()`: Returns a DataFrame of the same shape as the input DataFrame, with True where non-null values are present.\n",
        "\n",
        "   NOTE:there is no difference between `isna()` and `isnull()` methods.\n",
        "\n",
        "2. Counting Null Values:\n",
        "   - `df.isnull().sum()`: Returns the count of null values in each column of the DataFrame.\n",
        "\n",
        "3. Dropping Null Values:\n",
        "   - `df.dropna()`: Removes rows containing any null value from the DataFrame.\n",
        "   - `df.dropna(axis=1)`: Removes columns containing any null value from the DataFrame.\n",
        "\n",
        "4. Filling Null Values:\n",
        "   - `df.fillna(value)`: Fills null values with a specified value or using different filling methods such as forward fill (`ffill`) or backward fill (`bfill`).\n",
        "\n",
        "let's dive into these functions!\n"
      ],
      "metadata": {
        "id": "1wpoHWhzncMx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "paOSmdmfnb0x"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning) # Suppress the FutureWarning\n",
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "import pickle\n",
        "import pprint\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "churn = pd.read_csv(\"https://raw.githubusercontent.com/MonkeyWrenchGang/PythonBootcamp/main/day_3/data/churn_90k.csv\")"
      ],
      "metadata": {
        "id": "HN6GMW9Igffv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Data\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Here we have a typical real world churn dataset.\n",
        "\n",
        "```\n",
        "\"https://raw.githubusercontent.com/MonkeyWrenchGang/PythonBootcamp/main/day_3/data/churn_90k.csv\"\n",
        "```\n",
        "1. import the dataset with `read_csv()`\n",
        "2. eyeball the first 5 records with `head()`\n",
        "3. use info to describe the state of the dataset `.info()`\n",
        "\n",
        "## Summary of `.info()` in Pandas\n",
        "\n",
        "The `.info()` method in pandas provides a concise summary of a DataFrame. It returns the following information:\n",
        "\n",
        "- Total number of rows (observations) in the DataFrame.\n",
        "- Total number of columns in the DataFrame.\n",
        "- Name and data type of each column.\n",
        "- Number of non-null values in each column.\n",
        "- Memory usage of the DataFrame.\n",
        "\n",
        "The `.info()` method is useful for initial data exploration and quality assessment. It quickly reveals missing values and helps identify columns that may require further attention. The memory usage information allows users to optimize memory usage for large datasets.\n",
        "\n",
        "Usage: `df.info()`\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VqyaZVJLfOsq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mI5kAU2Af4Yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K5UvmZe5f4jU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4DP9b_dpf4sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary of `isna()` in Pandas\n",
        "\n",
        "The `isna()` method in pandas is used to identify missing or null values in a DataFrame. It returns a DataFrame with boolean values indicating the presence of null values.\n",
        "\n",
        "Key points about `isna()`:\n",
        "\n",
        "- It is a powerful method to detect missing values in a DataFrame or Series.\n",
        "- Returns `True` for each element in the DataFrame or Series that is a missing or null value, and `False` otherwise.\n",
        "- Missing or null values can be represented as `NaN` or `None` in pandas.\n",
        "- `isna()` is a useful tool for initial data exploration and data cleaning processes.\n",
        "\n",
        "Usage:\n",
        "\n",
        "- `df.isna()`: Returns a DataFrame of the same shape as the input DataFrame, with `True` where null values are present and `False` where non-null values are present.\n",
        "\n",
        "\n",
        "Example:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {\n",
        "    'Name': ['John', 'Emma', None],\n",
        "    'Age': [25, None, 32],\n",
        "    'City': ['New York', 'London', 'Paris']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Check for null values\n",
        "null_values = df.isna()\n",
        "print(null_values)\n",
        "\n",
        "```\n",
        "\n",
        "1. use churn.head(100).isna()\n",
        "  - kind of useless right?\n"
      ],
      "metadata": {
        "id": "b7YXr0C-f47z"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x3ChcAujgXBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary of `isna()`, `.sum()`, and `sum(axis=1)` in Pandas\n",
        "\n",
        "The combination of `isna()`, `.sum()`, and `sum(axis=1)` in pandas provides a powerful approach to handle missing or null values in a DataFrame.\n",
        "\n",
        "- `isna()` is used to identify missing or null values in a DataFrame. It returns a DataFrame or Series of the same shape as the original object, with boolean values indicating the presence of null values.\n",
        "\n",
        "- `.sum()` can be applied on the result of `isna()` to calculate the number of missing values in each column or row. It returns a Series with the sum of null values for each column (when applied on a DataFrame) or the sum of null values for each element (when applied on a Series).\n",
        "\n",
        "- `sum(axis=1)` calculates the sum of values across each row of a DataFrame, which is useful when determining the total number of missing values per row.\n",
        "\n",
        "Example:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {\n",
        "    'Name': ['John', 'Emma', None],\n",
        "    'Age': [25, None, 32],\n",
        "    'City': ['New York', 'London', 'Paris']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Check for null values in each column\n",
        "null_values_column = df.isna().sum()\n",
        "print(null_values_column)\n",
        "\n",
        "# Check for total null values in each row\n",
        "null_values_row = df.isna().sum(axis=1)\n",
        "print(null_values_row)\n",
        "```\n",
        "\n",
        "1. now use churn.isna().sum() do you get a nice columnar summary?\n",
        "2. next use churn.isna().sum(axis=1) this will give you a per-row count nulls\n",
        "3. create a dq column (yes new!)\n",
        "  ```\n",
        "  churn[\"dq\"] = churn.isna().sum(axis=1)\n",
        "  ```\n",
        "  - next filter for rows where dq >= 1\n",
        "4. churn[\"dq\"].sum() this will give you the total number of nulls in the dataset.\n"
      ],
      "metadata": {
        "id": "JIrv2weBgn9K"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T582HnnVgyO_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dMXFmSwCiSBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xg46kxWYiSHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Dropping Null Values\n",
        "   - `df.dropna()`: Removes rows containing any null value from the DataFrame.\n",
        "   - `df.dropna(axis=1)`: Removes columns containing any null value from the DataFrame.\n",
        "\n",
        "  1. create a clean churn dataset by removing rows with NAs\n",
        "  ```\n",
        "  churn_clean = churn.dropna()\n",
        "\n",
        "  ```\n",
        "  2. how many rows did you drop use .shape\n",
        "  3. can you print the difference of churn.shape[0] - churn_clean.shape[0] using print and .format()?"
      ],
      "metadata": {
        "id": "3je9jp7MiSx3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xN7bGr5kiQx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8rMaE76ajVfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SP6NVulOjVh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Filling Null Values\n",
        "\n",
        "\n",
        "---\n",
        "## Filling Null Values with Mean or Median\n",
        "\n",
        "Instead of dropping null values from a DataFrame, an alternative approach is to fill them in with the mean or median of the column. This allows for the retention of valuable data and avoids losing information.\n",
        "\n",
        "The mean represents the average value of a numerical column, while the median represents the middle value when the data is sorted. Filling null values with these central tendency measures can help preserve the overall distribution and characteristics of the data.\n",
        "\n",
        "Pandas provides convenient methods to achieve this:\n",
        "\n",
        "1. Filling with Mean:\n",
        "   - `df.fillna(df.mean())`: Fills null values with the mean of each column.\n",
        "\n",
        "2. Filling with Median:\n",
        "   - `df.fillna(df.median())`: Fills null values with the median of each column.\n",
        "\n",
        "It is important to note that filling null values with central tendency measures assumes that the mean or median is **representative of the missing values**. However, this will introduce biases or distortions especially if the data has outliers or a skewed distribution.\n",
        "\n",
        "Considerations:\n",
        "- It is advisable to apply mean or median filling on numerical columns rather than categorical columns.\n",
        "- Be cautious when using mean or median filling in the presence of outliers or data with significant deviations from normality.\n",
        "\n",
        "1. create a new churn dataset churn_clean2 using one of the methods above, use describe() to compare the mean & median (50% percentile) do you see a difference?\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RBXe1DFBjZYF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tdZRTlvLj_la"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iM4T7PQuj_p2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LikZSiX8kAOB"
      }
    }
  ]
}